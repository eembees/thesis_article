\begin{abstract}
Autoregressive convolutional neural networks such as WaveNet are powerful models that have recently achieved state-of-the-art results on both text-to-speech tasks and language modelling.
In spite of this, they have so-far been unable to generate coherent speech samples when learnt from audio alone.
The original configuration of WaveNet uses repeated blocks of dilated convolutions to reach a receptive field of 300 ms. 
In this work, we test hypotheses relating to the role of WaveNet's receptive field in learning to unconditionally generate coherent speech when not conditioned on auxiliary signals such as text. 
We also examine the usefulness of the learned representations for the downstream task of automatic speech recognition. 
By transforming the input data to stacks of multiple audio samples per timestep, we increase the receptive field to up to 5 seconds.
We find that enlarging the receptive field alone is insufficient to generate coherent samples.
We also provide evidence that WaveNets create representations of speech that are helpful in downstream tasks. 
Finally, we find that WaveNets lack capability to model natural language and argue that this is the limiting factor for direct speech generation. 

% ORIGINAL 17/1
% Autoregressive Convolutional Neural Networks are powerful models that have recently achieved state-of-the-art results on both text-to-speech tasks and language modelling.
% In spite of this, no reults have been shown to generate realistic speech samples learnt from audio alone.
% The main component of WaveNets, dilated convolutions, give receptive fields of up to 300 ms when stacked.
% By transforming the input data to stacks of multiple audio samples per timestep, we increase these receptive fields to up to 5 seconds.
% We find that enlarging the receptive field alone is insufficient to generate semantically coherent samples.
% We provide evidence that WaveNets create representations of speech that are helpful in downstream tasks. 
% We find that WaveNets lack capability to model natural language and argue that this is the limiting factor for direct speech generation. 



% Accurate and realistic sequence modeling is essential in various fields, including speech modeling, music generation, protein and DNA sequencing, and financial technology.
% This work investigates WaveNet, a fully convolutional, feed-forward model for next-step prediction, across a range of sequence modeling tasks. 
% First, we investigate WaveNet's capabilities for unconditioned sequence generation by increasing the receptive field for audio modeling.
% Second, we investigate whether WaveNet extracts semantic information using latent representations extracted directly from trained WaveNets. 
% Third, we analyze and test whether a WaveNet architecture can be made suitable for language modeling. 
% Fourth, we apply the modified WaveNet architecture to existing protein sequence datasets and explore its generative capacity compared to other probabilistic protein sequence models.
\end{abstract}